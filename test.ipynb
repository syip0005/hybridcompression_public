{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc26a4fb",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ea198e-2853-4623-97b8-d37721eb9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import _init_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459c9975-0e56-4772-8d05-c879b5c7d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecb4f7a-3318-49b2-bf95-a875a33123b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f242c5-201a-49dc-9b48-d53952bcbb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module '_init_paths' from '/fs03/au31/scotty/hybridcompression/_init_paths.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(_init_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ac7ff1-4255-46ee-844f-e62b2facb02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import dataloader\n",
    "from models import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7617ed5-73d0-4767-a54a-4aef8f086001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.models' from '/fs03/au31/scotty/hybridcompression/lib/models/models.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(dataloader)\n",
    "reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d14f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59508a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddb462",
   "metadata": {},
   "source": [
    "AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d1829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=False, \n",
    "#                                       no_rows = 60, wide_freq = 60, reshape_factor = 1,\n",
    "#                                       mode = 'fc')\n",
    "# train_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=True, \n",
    "#                                        no_rows = 60, wide_freq = 60, reshape_factor = 1,\n",
    "#                                        mode = 'fc'\n",
    "#                                       )\n",
    "\n",
    "# model = models.AE(input_days = 60, latent_n = 300, dropout = .1, wide_freq = 60).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f245e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = dataloader.CERN_Dataset_V3(folder_path = './dataset/interim/', train=False, \n",
    "#                                       no_days = 12, reshape_factor = 2,\n",
    "#                                       mode = 'fc')\n",
    "# train_set = dataloader.CERN_Dataset_V3(folder_path = './dataset/interim/', train=True, \n",
    "#                                        no_days = 12, reshape_factor = 2,\n",
    "#                                        mode = 'fc'\n",
    "#                                       )\n",
    "\n",
    "# model = models.AE(input_days = 12, latent_n = 48, dropout = .1, wide_freq = 48).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed6d18",
   "metadata": {},
   "source": [
    "SCSAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e05b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRED processed.\n",
      "DRED processed.\n"
     ]
    }
   ],
   "source": [
    "# test_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=False, \n",
    "#                                       no_rows = 60, wide_freq = 60, reshape_factor = 1,\n",
    "#                                       mode = 'cnn')\n",
    "# train_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=True, \n",
    "#                                        no_rows = 60, wide_freq = 60, reshape_factor = 1,\n",
    "#                                        mode = 'cnn'\n",
    "#                                       )\n",
    "\n",
    "# model = models.SCSAE(latent_n = 576, dropout = .1, input_days = 60, wide_freq = 60, \n",
    "#                      reshape_factor = 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6c34f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=False, \n",
    "#                                       no_rows = 12, wide_freq = 48, reshape_factor = 2,\n",
    "#                                       mode = 'cnn')\n",
    "# train_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=True, \n",
    "#                                        no_rows = 12, wide_freq = 48, reshape_factor = 2,\n",
    "#                                        mode = 'cnn'\n",
    "#                                       )\n",
    "\n",
    "# model = models.SCSAE(latent_n = 48, dropout = .1, input_days = 12, wide_freq = 48, \n",
    "#                      reshape_factor = 2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ca1cb7f-fff4-4fe2-8867-bc826fc56472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = dataloader.CERN_Dataset_V3(folder_path = './dataset/interim/', train=False, \n",
    "#                                       no_days = 12, reshape_factor = 2,\n",
    "#                                       mode = 'cnn')\n",
    "# train_set = dataloader.CERN_Dataset_V3(folder_path = './dataset/interim/', train=True, \n",
    "#                                        no_days = 12, reshape_factor = 2,\n",
    "#                                        mode = 'cnn'\n",
    "#                                       )\n",
    "\n",
    "model = models.SCSAE(latent_n = 300, dropout = .1, input_days = 60, wide_freq = 60, \n",
    "                     reshape_factor = 1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b515dc8",
   "metadata": {},
   "source": [
    "HAE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f6e9fdaf-6e2c-474d-82c3-837770fa1fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIDE_FREQ = 20\n",
    "# NO_ROWS = 240\n",
    "\n",
    "# test_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=False, \n",
    "#                                       no_rows = NO_ROWS, wide_freq = WIDE_FREQ, reshape_factor = 1,\n",
    "#                                       mode = 'cnn')\n",
    "# train_set = dataloader.DRED_Dataset(folder_path = './dataset/interim/', train=True, \n",
    "#                                        no_rows = NO_ROWS, wide_freq = WIDE_FREQ, reshape_factor = 1,\n",
    "#                                        mode = 'cnn'\n",
    "#                                       )\n",
    "\n",
    "# model = models.HAE_V2(latent_n = 300, dropout = .1, input_days = NO_ROWS, \n",
    "#                    wide_freq = WIDE_FREQ, reshape_factor = 1, device = 'cuda').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ecb96aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = dataloader.CERN_Dataset_V3(folder_path = './dataset/interim/', train=False, \n",
    "#                                       no_days = 7, reshape_factor = 1,\n",
    "#                                       mode = 'cnn')\n",
    "# train_set = dataloader.CERN_Dataset_V3(folder_path = './dataset/interim/', train=True, \n",
    "#                                        no_days = 7, reshape_factor = 1,\n",
    "#                                        mode = 'cnn'\n",
    "#                                       )\n",
    "\n",
    "# model = models.HAE_V2(latent_n = 48, dropout = .1, input_days = 7, \n",
    "#                    wide_freq = 48, reshape_factor = 1, device = 'cuda').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "816bf959-0210-4309-9242-51407a9fa2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.HAE_V2(latent_n = 300, dropout = .1, input_days = 60, \n",
    "                   wide_freq = 60, reshape_factor = 1, device = 'cuda').cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c8b1b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3ac4a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948556"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f65b02f7-73b4-4ec7-a1ae-1949ce220c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SCSAE_Encoder(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3): SeparableConv2d(\n",
       "    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
       "    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=576, bias=True)\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e895d065-148f-4b05-884f-2ae2431bcb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_parameters(model.encoder.fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21a4600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size = 1)\n",
    "test_loader = DataLoader(test_set, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3dbb9b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 60, 60])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_record = next(iter(train_loader))[0].cuda()\n",
    "test_record.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "854a3eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 576])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder(test_record).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ae625ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 60, 60])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model(test_record)\n",
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f56fb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e236863b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████████████████▏                                                                                                                      | 252/1440 [00:02<00:11, 100.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_97909/1691046144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mepoch_train_loss_avg\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlearn/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlearn/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlearn/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlearn/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    \n",
    "    ### TRAIN\n",
    "    \n",
    "    model.train()\n",
    "    epoch_train_loss_avg = 0\n",
    "\n",
    "    \n",
    "    for input, input_noisy in tqdm.tqdm(train_loader):\n",
    "        \n",
    "        input = input.cuda()\n",
    "        out, _ = model(input)\n",
    "        loss = criterion(out, input)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            epoch_train_loss_avg += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_train_loss_avg /= len(train_loader)\n",
    "    \n",
    "    ### VALIDATE\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_val_loss_avg = 0\n",
    "\n",
    "    for input, input_noisy in tqdm.tqdm(test_loader):\n",
    "        \n",
    "        input = input.cuda()\n",
    "        out, _ = model(input) \n",
    "        loss = criterion(out, input)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            epoch_val_loss_avg += loss.item()\n",
    "            \n",
    "    epoch_val_loss_avg /= len(test_loader)\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1} | Train Loss: {epoch_train_loss_avg: .3f} | Val Loss: {epoch_val_loss_avg: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b1fe4",
   "metadata": {},
   "source": [
    "***\n",
    "#### Shape Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835b1a7c-3bdc-4cb4-a0b6-c90dfc1ac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_conv_shape_calculator(output_height, output_width, kernel_shape, stride, padding, in_filters,\n",
    "                                 kernel_height = None, kernel_width = None):\n",
    "    \n",
    "    \"\"\"Calculates inverse of a convolution\n",
    "    \"\"\"\n",
    "        \n",
    "    if kernel_shape is not None:\n",
    "        kernel_height = kernel_shape\n",
    "        kernel_width = kernel_shape\n",
    "    \n",
    "    input_height = int(kernel_height - 2 * padding + (output_height -1 ) * stride)\n",
    "    input_width = int(kernel_width - 2 * padding + (output_width -1 ) * stride)\n",
    "    \n",
    "    return (in_filters, input_height, input_width)\n",
    "    \n",
    "def inverse_tconv_shape_calculator(output_height, output_width, kernel_shape, \n",
    "                                   stride, padding, out_padding, filters,\n",
    "                                  kernel_height = None, kernel_width = None,\n",
    "                                  stride_height = None, stride_width = None,\n",
    "                                  padding_height = None, padding_width = None,\n",
    "                                  out_padding_height = None, out_padding_width = None):\n",
    "\n",
    "    \"\"\"Calculates resulting shape of transposed convolution\n",
    "    \"\"\"\n",
    "        \n",
    "    if kernel_shape is not None:\n",
    "        kernel_height = kernel_shape\n",
    "        kernel_width = kernel_shape\n",
    "    if stride is not None:\n",
    "        stride_height = stride\n",
    "        stride_width = stride\n",
    "    if padding is not None:\n",
    "        padding_height = padding\n",
    "        padding_width = padding\n",
    "    if out_padding is not None:\n",
    "        out_padding_height = out_padding\n",
    "        out_padding_width = out_padding\n",
    "    \n",
    "    input_height_ = int((output_height - 1 - out_padding_height - (kernel_height - 1) + 2*padding_height) / stride_height + 1)\n",
    "    input_width_ = int((output_width - 1 - out_padding_width - (kernel_width - 1) + 2*padding_width) / stride_width + 1)\n",
    "\n",
    "    return (filters, input_height_, input_width_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68f5341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_calculator(input_height, input_width, kernel_height, kernel_width, stride_height,\n",
    "                    stride_width, input_filters):\n",
    "\n",
    "    \"\"\"Calculates resulting shape of pooling layer\n",
    "    \"\"\"\n",
    "\n",
    "    output_height_ = int(numpy.floor((input_height - kernel_height) / stride_height) + 1)\n",
    "    output_width_ = int(numpy.floor((input_width - kernel_width) / stride_width) + 1)\n",
    "\n",
    "    return (input_filters, output_height_, output_width_)\n",
    "\n",
    "def conv_shape_calculator(input_height, input_width, kernel_shape, stride, padding, filters,\n",
    "                         kernel_height = None, kernel_width = None):\n",
    "\n",
    "    \"\"\"Calculates resulting shape of convolution\n",
    "    \"\"\"\n",
    "    \n",
    "    if kernel_shape is not None:\n",
    "        kernel_height = kernel_shape\n",
    "        kernel_width = kernel_shape\n",
    "        \n",
    "\n",
    "    output_height_ = int(numpy.floor((input_height + 2*padding - kernel_height) / stride) + 1)\n",
    "    output_width_ = int(numpy.floor((input_width + 2*padding - kernel_width) / stride) + 1)\n",
    "\n",
    "    return (filters, output_height_, output_width_)\n",
    "\n",
    "def tconv_shape_calculator(input_height, input_width, kernel_shape, stride, padding, out_padding, filters,\n",
    "                          kernel_height = None, kernel_width = None,\n",
    "                                  stride_height = None, stride_width = None,\n",
    "                                  padding_height = None, padding_width = None,\n",
    "                                  out_padding_height = None, out_padding_width = None):\n",
    "\n",
    "    \"\"\"Calculates resulting shape of transposed convolution\n",
    "    \"\"\"\n",
    "    \n",
    "    if kernel_shape is not None:\n",
    "        kernel_height = kernel_shape\n",
    "        kernel_width = kernel_shape\n",
    "    if stride is not None:\n",
    "        stride_height = stride\n",
    "        stride_width = stride\n",
    "    if padding is not None:\n",
    "        padding_height = padding\n",
    "        padding_width = padding\n",
    "    if out_padding is not None:\n",
    "        out_padding_height = out_padding\n",
    "        out_padding_width = out_padding\n",
    "\n",
    "\n",
    "    output_height_ = int((input_height - 1) * stride_height - 2 * padding_height + (kernel_height - 1) + out_padding_height + 1)\n",
    "    output_width_ = int((input_width - 1) * stride_width - 2 * padding_width +(kernel_width - 1) + out_padding_width + 1)\n",
    "\n",
    "    return (filters, output_height_, output_width_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbc5d6-a77d-441a-8f7f-ba2ccff7c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1, 12, 48)\n",
    "shape = conv_shape_calculatorlator(shape[1], shape[2], )\n",
    "shape = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be95e2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 7, 48)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (1, 7, 48)\n",
    "shape = inverse_conv_shape_calculator(shape[1], shape[2],\n",
    "                                            kernel_shape = 1, stride = 1, padding = 0, in_filters = 32) # conv4\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2276c953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 4, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = inverse_tconv_shape_calculator(shape[1], shape[2],\n",
    "                                            kernel_shape = 2, stride = 2, padding = 1, out_padding = None, \n",
    "                                            filters = 64, out_padding_height = 1, out_padding_width = 0) # tconv2\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b8c7c58-21ff-4b14-9082-e87c748db5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = inverse_tconv_shape_calculator(shape[1], shape[2],\n",
    "                                            kernel_shape = 5, stride = 2, padding = 1, out_padding = None, \n",
    "                                            filters = 64, out_padding_height=1, out_padding_width=0) # tconv1\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_shape = shape\n",
    "decoder_shape = tconv_shape_calculator(decoder_shape[1], decoder_shape[2], \n",
    "                                       kernel_shape = 5, stride = 2, padding= 1, out_padding= None,\n",
    "                                       filters= 64, out_padding_height = 1, out_padding_width = 0)\n",
    "decoder_shape = tconv_shape_calculator(decoder_shape[1], decoder_shape[2], \n",
    "                                       kernel_shape = 2, stride = 2, padding= 1, out_padding= None,\n",
    "                                       filters= 32, out_padding_height = 1, out_padding_width = 0)\n",
    "decoder_shape = conv_shape_calculator(decoder_shape[1], decoder_shape[2], \n",
    "                                      1, 1, 0, 1)\n",
    "decoder_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd15c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_record.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b53fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "12 % 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate shape\n",
    "shape = (1, input_days * reshape_factor, wide_freq / reshape_factor)\n",
    "shape = inverse_conv_shape_calculator(shape[1], shape[2],\n",
    "                                            kernel_shape = 1, stride = 1, padding = 0, in_filters = 32) # conv4\n",
    "shape = inverse_tconv_shape_calculator(shape[1], shape[2],\n",
    "                                            kernel_shape = 3, stride = 2, padding = 1, out_padding = 1, filters = 64) # tconv2\n",
    "shape = inverse_tconv_shape_calculator(shape[1], shape[2],\n",
    "                                            kernel_shape = 3, stride = 2, padding = 1, out_padding = 1, filters = 64) # tconv1\n",
    "self.shape = shape\n",
    "\n",
    "# Decoder\n",
    "self.fc2 = nn.Linear(latent_n, shape[0] * shape[1] * shape[2])\n",
    "self.tconv1 = nn.ConvTranspose2d(in_channels=64, out_channels = 64, \n",
    "                                 kernel_size = 3, stride=2, padding=1, output_padding=1, bias=False) # pad and outpad to make it work\n",
    "self.tconv2 = nn.ConvTranspose2d(in_channels=64, out_channels = 32, \n",
    "                                 kernel_size = 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "self.conv4 = nn.Conv2d(in_channels=32, out_channels = 1, kernel_size = (1,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
